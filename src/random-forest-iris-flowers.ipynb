{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pkg_pandas\n",
    "import math as pkg_math\n",
    "from matplotlib import pyplot as pkg_plot\n",
    "from sklearn import model_selection as pkg_model_selection\n",
    "from sklearn import preprocessing as pkg_preprocessing\n",
    "from sklearn import tree as pkg_tree\n",
    "from sklearn import metrics as pkg_metrics\n",
    "from sklearn import datasets as pkg_datasets\n",
    "from sklearn import ensemble as pkg_ensemble\n",
    "import seaborn as pkg_seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DESCR',\n",
       " 'data',\n",
       " 'data_module',\n",
       " 'feature_names',\n",
       " 'filename',\n",
       " 'frame',\n",
       " 'target',\n",
       " 'target_names']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_data = pkg_datasets.load_iris()\n",
    "dir(loaded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Names = ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "Target Names = ['setosa' 'versicolor' 'virginica']\n",
      "Column\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nFeature Names = {}\\nTarget Names = {}\\nColumn\".format(\\\n",
    "    loaded_data.feature_names, loaded_data.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = []\n",
    "for feature_name in loaded_data.feature_names:\n",
    "    column_name = feature_name.replace(' ', '_').replace('(','').replace(')','')\n",
    "    column_names.append(column_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length_cm</th>\n",
       "      <th>sepal_width_cm</th>\n",
       "      <th>petal_length_cm</th>\n",
       "      <th>petal_width_cm</th>\n",
       "      <th>flower_number</th>\n",
       "      <th>flower_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length_cm  sepal_width_cm  petal_length_cm  petal_width_cm  \\\n",
       "0              5.1             3.5              1.4             0.2   \n",
       "1              4.9             3.0              1.4             0.2   \n",
       "2              4.7             3.2              1.3             0.2   \n",
       "3              4.6             3.1              1.5             0.2   \n",
       "4              5.0             3.6              1.4             0.2   \n",
       "\n",
       "   flower_number flower_name  \n",
       "0              0      setosa  \n",
       "1              0      setosa  \n",
       "2              0      setosa  \n",
       "3              0      setosa  \n",
       "4              0      setosa  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_df = pkg_pandas.DataFrame(loaded_data.data, columns=column_names)\n",
    "loaded_df['flower_number'] = loaded_data.target\n",
    "loaded_df['flower_name'] = loaded_df['flower_number'].apply(lambda fnum: loaded_data.target_names[fnum])\n",
    "loaded_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize\n",
    "baseline_df = loaded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Baseline Split - Train and Test ===\n",
      "Lengths: Baseline = 150, Train = 120, Test = 30\n"
     ]
    }
   ],
   "source": [
    "output_column_name = 'flower_number'\n",
    "baseline_outputs = baseline_df[output_column_name]\n",
    "baseline_inputs = baseline_df.drop(columns=[output_column_name, 'flower_name'])\n",
    "\n",
    "train_inputs, test_inputs, train_outputs, test_outputs  = \\\n",
    "    pkg_model_selection.train_test_split(baseline_inputs, baseline_outputs, test_size=0.20)\n",
    "\n",
    "print(\"=== Baseline Split - Train and Test ===\")\n",
    "print(\"Lengths: Baseline = {}, Train = {}, Test = {}\".format(len(baseline_inputs), len(train_inputs), len(test_inputs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model: Train (Fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:: Scores(gini_sqrt_balanced_20): Baseline = 0.9933333333333333, Train = 1.0, Test = 0.9666666666666667\n",
      "DEBUG:: Scores(gini_sqrt_balanced_40): Baseline = 0.9866666666666667, Train = 1.0, Test = 0.9333333333333333\n",
      "DEBUG:: Scores(gini_sqrt_balanced_70): Baseline = 0.9933333333333333, Train = 1.0, Test = 0.9666666666666667\n",
      "DEBUG:: Scores(gini_sqrt_balanced_100): Baseline = 0.9866666666666667, Train = 1.0, Test = 0.9333333333333333\n",
      "DEBUG:: Scores(gini_sqrt_balanced_150): Baseline = 0.9866666666666667, Train = 1.0, Test = 0.9333333333333333\n",
      "DEBUG:: Scores(gini_sqrt_balanced_250): Baseline = 0.9933333333333333, Train = 1.0, Test = 0.9666666666666667\n",
      "DEBUG:: Scores(gini_sqrt_balanced_subsample_20): Baseline = 0.9866666666666667, Train = 1.0, Test = 0.9333333333333333\n",
      "DEBUG:: Scores(gini_sqrt_balanced_subsample_40): Baseline = 0.9866666666666667, Train = 1.0, Test = 0.9333333333333333\n",
      "DEBUG:: Scores(gini_sqrt_balanced_subsample_70): Baseline = 0.9933333333333333, Train = 1.0, Test = 0.9666666666666667\n",
      "DEBUG:: Scores(gini_sqrt_balanced_subsample_100): Baseline = 0.9866666666666667, Train = 1.0, Test = 0.9333333333333333\n",
      "DEBUG:: Scores(gini_sqrt_balanced_subsample_150): Baseline = 0.9866666666666667, Train = 1.0, Test = 0.9333333333333333\n",
      "DEBUG:: Scores(gini_sqrt_balanced_subsample_250): Baseline = 0.9933333333333333, Train = 1.0, Test = 0.9666666666666667\n",
      "DEBUG:: Scores(gini_log2_balanced_20): Baseline = 0.9933333333333333, Train = 1.0, Test = 0.9666666666666667\n",
      "DEBUG:: Scores(gini_log2_balanced_40): Baseline = 0.9866666666666667, Train = 1.0, Test = 0.9333333333333333\n",
      "DEBUG:: Scores(gini_log2_balanced_70): Baseline = 0.9866666666666667, Train = 1.0, Test = 0.9333333333333333\n",
      "DEBUG:: Scores(gini_log2_balanced_100): Baseline = 0.9933333333333333, Train = 1.0, Test = 0.9666666666666667\n",
      "DEBUG:: Scores(gini_log2_balanced_150): Baseline = 0.9866666666666667, Train = 1.0, Test = 0.9333333333333333\n",
      "DEBUG:: Scores(gini_log2_balanced_250): Baseline = 0.9866666666666667, Train = 1.0, Test = 0.9333333333333333\n",
      "DEBUG:: Scores(gini_log2_balanced_subsample_20): Baseline = 0.9933333333333333, Train = 1.0, Test = 0.9666666666666667\n",
      "DEBUG:: Scores(gini_log2_balanced_subsample_40): Baseline = 0.9866666666666667, Train = 1.0, Test = 0.9333333333333333\n",
      "DEBUG:: Scores(gini_log2_balanced_subsample_70): Baseline = 0.9866666666666667, Train = 1.0, Test = 0.9333333333333333\n",
      "DEBUG:: Scores(gini_log2_balanced_subsample_100): Baseline = 0.9866666666666667, Train = 1.0, Test = 0.9333333333333333\n",
      "DEBUG:: Scores(gini_log2_balanced_subsample_150): Baseline = 0.9866666666666667, Train = 1.0, Test = 0.9333333333333333\n",
      "DEBUG:: Scores(gini_log2_balanced_subsample_250): Baseline = 0.9933333333333333, Train = 1.0, Test = 0.9666666666666667\n",
      "DEBUG:: Scores(entropy_sqrt_balanced_20): Baseline = 0.9866666666666667, Train = 1.0, Test = 0.9333333333333333\n",
      "DEBUG:: Scores(entropy_sqrt_balanced_40): Baseline = 0.9866666666666667, Train = 1.0, Test = 0.9333333333333333\n",
      "DEBUG:: Scores(entropy_sqrt_balanced_70): Baseline = 0.9933333333333333, Train = 1.0, Test = 0.9666666666666667\n",
      "DEBUG:: Scores(entropy_sqrt_balanced_100): Baseline = 0.9866666666666667, Train = 1.0, Test = 0.9333333333333333\n",
      "DEBUG:: Scores(entropy_sqrt_balanced_150): Baseline = 0.9933333333333333, Train = 1.0, Test = 0.9666666666666667\n",
      "DEBUG:: Scores(entropy_sqrt_balanced_250): Baseline = 0.9866666666666667, Train = 1.0, Test = 0.9333333333333333\n",
      "DEBUG:: Scores(entropy_sqrt_balanced_subsample_20): Baseline = 0.9866666666666667, Train = 1.0, Test = 0.9333333333333333\n",
      "DEBUG:: Scores(entropy_sqrt_balanced_subsample_40): Baseline = 0.9933333333333333, Train = 1.0, Test = 0.9666666666666667\n",
      "DEBUG:: Scores(entropy_sqrt_balanced_subsample_70): Baseline = 0.9933333333333333, Train = 1.0, Test = 0.9666666666666667\n",
      "DEBUG:: Scores(entropy_sqrt_balanced_subsample_100): Baseline = 0.9933333333333333, Train = 1.0, Test = 0.9666666666666667\n",
      "DEBUG:: Scores(entropy_sqrt_balanced_subsample_150): Baseline = 0.9933333333333333, Train = 1.0, Test = 0.9666666666666667\n",
      "DEBUG:: Scores(entropy_sqrt_balanced_subsample_250): Baseline = 0.9933333333333333, Train = 1.0, Test = 0.9666666666666667\n",
      "DEBUG:: Scores(entropy_log2_balanced_20): Baseline = 0.9866666666666667, Train = 1.0, Test = 0.9333333333333333\n",
      "DEBUG:: Scores(entropy_log2_balanced_40): Baseline = 0.9933333333333333, Train = 1.0, Test = 0.9666666666666667\n",
      "DEBUG:: Scores(entropy_log2_balanced_70): Baseline = 0.9866666666666667, Train = 1.0, Test = 0.9333333333333333\n",
      "DEBUG:: Scores(entropy_log2_balanced_100): Baseline = 0.9866666666666667, Train = 1.0, Test = 0.9333333333333333\n",
      "DEBUG:: Scores(entropy_log2_balanced_150): Baseline = 0.9866666666666667, Train = 1.0, Test = 0.9333333333333333\n",
      "DEBUG:: Scores(entropy_log2_balanced_250): Baseline = 0.9866666666666667, Train = 1.0, Test = 0.9333333333333333\n",
      "DEBUG:: Scores(entropy_log2_balanced_subsample_20): Baseline = 0.98, Train = 0.9916666666666667, Test = 0.9333333333333333\n",
      "DEBUG:: Scores(entropy_log2_balanced_subsample_40): Baseline = 0.9933333333333333, Train = 1.0, Test = 0.9666666666666667\n",
      "DEBUG:: Scores(entropy_log2_balanced_subsample_70): Baseline = 0.9933333333333333, Train = 1.0, Test = 0.9666666666666667\n",
      "DEBUG:: Scores(entropy_log2_balanced_subsample_100): Baseline = 0.9933333333333333, Train = 1.0, Test = 0.9666666666666667\n",
      "DEBUG:: Scores(entropy_log2_balanced_subsample_150): Baseline = 0.9933333333333333, Train = 1.0, Test = 0.9666666666666667\n",
      "DEBUG:: Scores(entropy_log2_balanced_subsample_250): Baseline = 0.9933333333333333, Train = 1.0, Test = 0.9666666666666667\n",
      "DEBUG:: Scores(log_loss_sqrt_balanced_20): Baseline = 0.9933333333333333, Train = 1.0, Test = 0.9666666666666667\n",
      "DEBUG:: Scores(log_loss_sqrt_balanced_40): Baseline = 0.9933333333333333, Train = 1.0, Test = 0.9666666666666667\n",
      "DEBUG:: Scores(log_loss_sqrt_balanced_70): Baseline = 0.9866666666666667, Train = 1.0, Test = 0.9333333333333333\n",
      "DEBUG:: Scores(log_loss_sqrt_balanced_100): Baseline = 0.9933333333333333, Train = 1.0, Test = 0.9666666666666667\n",
      "DEBUG:: Scores(log_loss_sqrt_balanced_150): Baseline = 0.9866666666666667, Train = 1.0, Test = 0.9333333333333333\n",
      "DEBUG:: Scores(log_loss_sqrt_balanced_250): Baseline = 0.9933333333333333, Train = 1.0, Test = 0.9666666666666667\n",
      "DEBUG:: Scores(log_loss_sqrt_balanced_subsample_20): Baseline = 0.9866666666666667, Train = 1.0, Test = 0.9333333333333333\n",
      "DEBUG:: Scores(log_loss_sqrt_balanced_subsample_40): Baseline = 0.9866666666666667, Train = 1.0, Test = 0.9333333333333333\n",
      "DEBUG:: Scores(log_loss_sqrt_balanced_subsample_70): Baseline = 0.9866666666666667, Train = 1.0, Test = 0.9333333333333333\n",
      "DEBUG:: Scores(log_loss_sqrt_balanced_subsample_100): Baseline = 0.9933333333333333, Train = 1.0, Test = 0.9666666666666667\n",
      "DEBUG:: Scores(log_loss_sqrt_balanced_subsample_150): Baseline = 0.9866666666666667, Train = 1.0, Test = 0.9333333333333333\n",
      "DEBUG:: Scores(log_loss_sqrt_balanced_subsample_250): Baseline = 0.9866666666666667, Train = 1.0, Test = 0.9333333333333333\n",
      "DEBUG:: Scores(log_loss_log2_balanced_20): Baseline = 0.9866666666666667, Train = 1.0, Test = 0.9333333333333333\n",
      "DEBUG:: Scores(log_loss_log2_balanced_40): Baseline = 0.9933333333333333, Train = 1.0, Test = 0.9666666666666667\n",
      "DEBUG:: Scores(log_loss_log2_balanced_70): Baseline = 0.9933333333333333, Train = 1.0, Test = 0.9666666666666667\n",
      "DEBUG:: Scores(log_loss_log2_balanced_100): Baseline = 0.9866666666666667, Train = 1.0, Test = 0.9333333333333333\n",
      "DEBUG:: Scores(log_loss_log2_balanced_150): Baseline = 0.9866666666666667, Train = 1.0, Test = 0.9333333333333333\n",
      "DEBUG:: Scores(log_loss_log2_balanced_250): Baseline = 0.9866666666666667, Train = 1.0, Test = 0.9333333333333333\n",
      "DEBUG:: Scores(log_loss_log2_balanced_subsample_20): Baseline = 0.9933333333333333, Train = 1.0, Test = 0.9666666666666667\n",
      "DEBUG:: Scores(log_loss_log2_balanced_subsample_40): Baseline = 0.9933333333333333, Train = 1.0, Test = 0.9666666666666667\n",
      "DEBUG:: Scores(log_loss_log2_balanced_subsample_70): Baseline = 0.9933333333333333, Train = 1.0, Test = 0.9666666666666667\n",
      "DEBUG:: Scores(log_loss_log2_balanced_subsample_100): Baseline = 0.9866666666666667, Train = 1.0, Test = 0.9333333333333333\n",
      "DEBUG:: Scores(log_loss_log2_balanced_subsample_150): Baseline = 0.9933333333333333, Train = 1.0, Test = 0.9666666666666667\n",
      "DEBUG:: Scores(log_loss_log2_balanced_subsample_250): Baseline = 0.9866666666666667, Train = 1.0, Test = 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "best_model = None\n",
    "best_params = []\n",
    "best_test_score = 0\n",
    "best_predicted_outputs = None\n",
    "\n",
    "for criteria_type in ['gini','entropy','log_loss']:\n",
    "    for feature_type in ['sqrt', 'log2']:\n",
    "        for class_weight_type in ['balanced', 'balanced_subsample']:\n",
    "            for estimator_count in [20, 40, 70, 100, 150, 250]:\n",
    "                # Parameter Combination\n",
    "                params = [criteria_type, feature_type, class_weight_type, str(estimator_count)]\n",
    "                param_name = '_'.join(params)\n",
    "\n",
    "                # Train\n",
    "                model = pkg_ensemble.RandomForestClassifier(n_estimators=estimator_count, criterion=criteria_type, max_features=feature_type, class_weight=class_weight_type)\n",
    "                model.fit(train_inputs, train_outputs)\n",
    "\n",
    "                # Test\n",
    "                predicted_outputs = model.predict(test_inputs)\n",
    "\n",
    "                # Score\n",
    "                baseline_score = model.score(baseline_inputs, baseline_outputs)\n",
    "                train_score = model.score(train_inputs, train_outputs)\n",
    "                test_score = model.score(test_inputs, test_outputs)\n",
    "                print(\"DEBUG:: Scores({}): Baseline = {}, Train = {}, Test = {}\".format(param_name, baseline_score, train_score, test_score))\n",
    "\n",
    "                if (best_test_score < test_score):\n",
    "                    best_model = model\n",
    "                    best_params = params\n",
    "                    best_test_score = test_score\n",
    "                    best_predicted_outputs = predicted_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "= = : Best Model : = =\n",
      "Params = ['gini', 'sqrt', 'balanced', '20'], Test Score = 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "print(\"= = : Best Model : = =\")\n",
    "print(\"Params = {}, Test Score = {}\".format(best_params, best_test_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9,  0,  0],\n",
       "       [ 0, 11,  1],\n",
       "       [ 0,  0,  9]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = pkg_metrics.confusion_matrix(y_true=test_outputs, y_pred=best_predicted_outputs)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "pkg_plot.figure(figsize=(4,3))\n",
    "pkg_plot.xlabel('Predicted')\n",
    "pkg_plot.xlabel('Actual')\n",
    "pkg_seaborn.heatmap(cm, annot=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
